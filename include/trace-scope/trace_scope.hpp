#pragma once
/**
 * @file trace_scope.hpp
 * @brief Single-header trace library (auto-generated)
 * 
 * This file is automatically generated from modular sources.
 * DO NOT EDIT THIS FILE DIRECTLY - edit the source modules instead.
 * 
 * Generated: 2025-10-27 22:27:57 UTC
 * Source modules: 12 files
 * 
 * Source files (in merge order):
 *   - platform.hpp
 *   - types/enums.hpp
 *   - types/event.hpp
 *   - types/stats.hpp
 *   - types/config.hpp
 *   - types/async_queue.hpp
 *   - types/ring.hpp
 *   - types/registry.hpp
 *   - types/scope.hpp
 *   - variables.hpp
 *   - functions.hpp
 *   - macros.hpp
 * 
 * To regenerate this file:
 *   python tools/merge_header.py --input include/trace-scope/trace_scope_modular --output include/trace-scope/trace_scope.hpp
 * 
 * Or use CMake (automatic):
 *   cmake --build . --target generate_header
 */

// Standard C++ includes
#include <algorithm>
#include <atomic>
#include <chrono>
#include <condition_variable>
#include <cstdarg>
#include <cstdint>
#include <cstdio>
#include <cstdio>  // For FILE*
#include <cstdlib>
#include <cstring>
#include <ctime>
#include <filesystem>
#include <functional>
#include <map>
#include <mutex>
#include <sstream>
#include <string>
#include <thread>
#include <vector>

// Platform-specific includes
#ifdef _WIN32
#include <windows.h>
#include <psapi.h>
// Undefine Windows macros that conflict with std::min/max
#undef min
#undef max
#elif defined(__APPLE__)
#include <mach/mach.h>
#include <mach/task.h>
#endif
#ifdef _WIN32
// Windows shared memory functions are in windows.h (already included)
#elif defined(__linux__) || defined(__APPLE__)
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#endif

// Build config defines
#ifndef TRC_SCOPE_API
      #define TRC_SCOPE_API
#endif
#ifndef TRC_ENABLED
#define TRC_ENABLED 1
#endif
#ifndef TRC_RING_CAP
#define TRC_RING_CAP 4096
#endif
#ifndef TRC_MSG_CAP
#define TRC_MSG_CAP 192
#endif
#ifndef TRC_DEPTH_MAX
#define TRC_DEPTH_MAX 512
#endif
#ifndef TRC_DOUBLE_BUFFER
#define TRC_DOUBLE_BUFFER 0  // Default: disabled to save memory (~1.2MB per thread)
#endif
#define TRC_NUM_BUFFERS 2
#define TRC_SCOPE_VERSION "0.14.1-alpha"
#define TRC_SCOPE_VERSION_MAJOR 0
#define TRC_SCOPE_VERSION_MINOR 14
#define TRC_SCOPE_VERSION_PATCH 1
#ifdef _WIN32
    localtime_s(&tm, &time_t_val);
#else
    localtime_r(&time_t_val, &tm);
#endif

// Single namespace
namespace trace {


// Cross-platform safe fopen wrapper to avoid deprecation warnings
inline FILE* safe_fopen(const char* filename, const char* mode) {
#ifdef _MSC_VER
    FILE* file = nullptr;
    if (fopen_s(&file, filename, mode) != 0) {
        return nullptr;
    }
    return file;
#else
    return std::fopen(filename, mode);
#endif
}

// Cross-platform safe tmpfile wrapper
inline FILE* safe_tmpfile() {
#ifdef _MSC_VER
    FILE* file = nullptr;
    return tmpfile_s(&file) == 0 ? file : nullptr;
#else
    return std::tmpfile();
#endif
}


/**
 * @brief Tracing output mode.
 *
 * Determines how trace events are captured and output:
 * - Buffered: Events stored in ring buffer, flushed manually (default, best performance)
 * - Immediate: Events printed immediately, no buffering (real-time, higher overhead)
 * - Hybrid: Events both buffered AND printed immediately (best of both worlds)
 */
enum class TracingMode {
    Buffered,   ///< Default: events buffered in ring buffer, manual flush required
    Immediate,  ///< Real-time output: bypass ring buffer, print immediately
    Hybrid      ///< Hybrid: buffer events AND print immediately for real-time + history
};

/**
 * @brief Flush behavior modes for scope exit.
 */
enum class FlushMode {
    NEVER,           ///< No auto-flush on scope exit
    OUTERMOST_ONLY,  ///< Flush only when depth returns to 0 (default)
    EVERY_SCOPE      ///< Flush on every scope exit (high overhead)
};

/**
 * @brief Shared memory usage modes.
 */
enum class SharedMemoryMode {
    AUTO,      ///< Auto-detect: use shared if DLL detected (default)
    DISABLED,  ///< Never use shared memory (force thread_local)
    ENABLED    ///< Always use shared memory
};

/**
 * @brief Output directory layout options
 */
enum class OutputLayout {
    Flat,      ///< All files in output_dir: output_dir/trace_*.trc
    ByDate,    ///< Organized by date: output_dir/2025-10-20/trace_*.trc
    BySession  ///< Organized by session: output_dir/session_001/trace_*.trc
};

/**
 * @brief Type of trace event
 */
enum class EventType : uint8_t {
    Enter = 0,  ///< Function entry
    Exit = 1,   ///< Function exit
    Msg = 2     ///< Message/log event
};


// Forward declarations
enum class EventType : uint8_t;

/**
 * @brief A single trace event stored in the ring buffer.
 *
 * Events are created for function entry/exit (via TRC_SCOPE) and
 * for log messages (via TRC_MSG).
 */
struct Event {
    uint64_t    ts_ns;                  ///< Timestamp in nanoseconds (system clock, wall-clock time)
    const char* func;                   ///< Function name (for enter/exit; null for msg)
    const char* file;                   ///< Source file path
    int         line;                   ///< Source line number
    int         depth;                  ///< Call stack depth (for indentation)
    uint32_t    tid;                    ///< Thread ID (hashed to 32-bit for display)
    uint8_t     color_offset;           ///< Thread color offset for colorize_depth mode
    EventType   type;                   ///< Event type (Enter/Exit/Msg)
    uint64_t    dur_ns;                 ///< Duration in nanoseconds (Exit only; 0 otherwise)
    char        msg[TRC_MSG_CAP + 1]; ///< Message text (Msg events only; empty otherwise)
    uint64_t    memory_rss = 0;          ///< RSS memory usage in bytes (when track_memory enabled)
};


/**
 * @brief Performance statistics for a single function.
 */
struct FunctionStats {
    const char* func_name;     ///< Function name
    uint64_t    call_count;   ///< Number of times function was called
    uint64_t    total_ns;     ///< Total execution time in nanoseconds
    uint64_t    min_ns;       ///< Minimum execution time in nanoseconds
    uint64_t    max_ns;       ///< Maximum execution time in nanoseconds
    uint64_t    memory_delta; ///< Memory delta in bytes (peak - start RSS)

    double avg_ns() const { return call_count > 0 ? (double)total_ns / call_count : 0.0; }
};

/**
 * @brief Per-thread performance statistics.
 */
struct ThreadStats {
    uint32_t tid;                                    ///< Thread ID
    std::vector<FunctionStats> functions;            ///< Function statistics for this thread
    uint64_t total_events;                          ///< Total events in this thread
    uint64_t peak_rss;                              ///< Peak RSS memory usage for this thread
};


// Forward declarations
enum class TracingMode;
enum class FlushMode;
enum class SharedMemoryMode;

/**
 * @brief Global configuration for trace output formatting and behavior.
 *
 * All settings can be modified at runtime before tracing begins.
 * Config changes during tracing are not thread-safe.
 */
struct Config {
    FILE* out = stdout;               ///< Output file stream (default: stdout)
    bool print_timing = true;         ///< Show function durations with auto-scaled units
    bool print_timestamp = false;     ///< Show ISO timestamps [YYYY-MM-DD HH:MM:SS.mmm] (opt-in)
    bool print_thread = true;         ///< Show thread ID in hex format
    bool auto_flush_at_exit = false;  ///< Automatically flush when outermost scope exits (opt-in)

    // Tracing mode
    TracingMode mode = TracingMode::Buffered;  ///< Tracing output mode (default: Buffered)
    FILE* immediate_out = nullptr;    ///< Separate output stream for immediate output in Hybrid mode (nullptr = use 'out')
    float auto_flush_threshold = 0.9f; ///< Auto-flush when buffer reaches this fraction full in Hybrid mode (0.0-1.0, default 0.9 = 90%)

    // Async immediate mode configuration
    int immediate_flush_interval_ms = 1;  ///< Flush interval for async immediate mode (default: 1ms, 0 = flush every event)
    size_t immediate_queue_size = 128;    ///< Max queue size hint for async immediate mode (default: 128)

    // Prefix content control
    bool include_file_line = true;    ///< Include filename:line in prefix block

    // Filename rendering options
    bool include_filename = true;     ///< Show filename in prefix
    bool show_full_path = false;      ///< Show full path vs basename only
    int  filename_width = 20;         ///< Fixed width for filename column
    int  line_width     = 5;          ///< Fixed width for line number

    // Function name rendering options
    bool include_function_name = true;  ///< Show function name in prefix (line number pairs with this)
    int  function_width = 20;           ///< Fixed width for function name column

    // Indentation and marker visualization
    bool show_indent_markers = true;    ///< Show visual markers for indentation levels
    const char* indent_marker = "| ";   ///< Marker for each indentation level (e.g., "| ", "  ", "│ ")
    const char* enter_marker = "-> ";   ///< Marker for function entry (e.g., "-> ", "↘ ", "► ")
    const char* exit_marker = "<- ";    ///< Marker for function exit (e.g., "<- ", "↖ ", "◄ ")
    const char* msg_marker = "- ";      ///< Marker for message events (e.g., "- ", "• ", "* ")

    // ANSI color support
    bool colorize_depth = false;        ///< Colorize output based on call depth (opt-in, ANSI colors)

    // Double-buffering for high-frequency tracing
    bool use_double_buffering = false;  ///< Enable double-buffering (opt-in, eliminates flush race conditions)
                                        ///< Pros: Safe concurrent write/flush, zero disruption, better for high-frequency tracing
                                        ///< Cons: 2x memory per thread (~4MB default), slightly more complex
                                        ///< Use when: Generating millions of events/sec with frequent flushing

    // Filtering and selective tracing
    struct {
        std::vector<std::string> include_functions;  ///< Include function patterns (empty = trace all)
        std::vector<std::string> exclude_functions;  ///< Exclude function patterns (higher priority than include)
        std::vector<std::string> include_files;      ///< Include file patterns (empty = trace all)
        std::vector<std::string> exclude_files;      ///< Exclude file patterns (higher priority than include)
        int max_depth = -1;                          ///< Maximum trace depth (-1 = unlimited)
    } filter;

    // Performance metrics and memory tracking
    bool print_stats = false;        ///< Print performance statistics at program exit
    bool track_memory = false;       ///< Sample RSS memory at each trace point (low overhead ~1-5µs)

    // Flush and shared memory behavior
    FlushMode flush_mode = FlushMode::OUTERMOST_ONLY;  ///< When to auto-flush on scope exit
    SharedMemoryMode shared_memory_mode = SharedMemoryMode::AUTO;  ///< Shared memory usage mode

    // Binary dump configuration
    const char* dump_prefix = "trace";  ///< Filename prefix for binary dumps (default: "trace")
    const char* dump_suffix = ".trc";   ///< File extension for binary dumps (default: ".trc")
    const char* output_dir = nullptr;   ///< Output directory (nullptr = current directory)

    /// Output directory layout options
    enum class OutputLayout {
        Flat,      ///< All files in output_dir: output_dir/trace_*.trc
        ByDate,    ///< Organized by date: output_dir/2025-10-20/trace_*.trc
        BySession  ///< Organized by session: output_dir/session_001/trace_*.trc
    };
    OutputLayout output_layout = OutputLayout::Flat;  ///< Directory structure layout (default: Flat)
    int current_session = 0;  ///< Session number for BySession layout (0 = auto-increment)

    /**
     * @brief Load configuration from INI file.
     *
     * Parses an INI file and applies settings to this Config instance.
     * Supports sections: [output], [display], [formatting], [markers], [modes],
     *                     [filter], [performance], [dump]
     *
     * @param path Path to INI file (relative or absolute)
     * @return true on success, false if file not found or critical error
     *
     * Example INI format:
     * @code
     * [display]
     * print_timing = true
     * print_timestamp = false
     *
     * [dump]
     * prefix = trace
     * suffix = .trc
     * output_dir = logs
     * layout = date
     *
     * [markers]
     * indent_marker = |
     * enter_marker = ->
     * @endcode
     */
    inline bool load_from_file(const char* path);
};


// Forward declarations
struct Event;
inline void print_event(const Event& e, FILE* out);

/**
 * @brief Asynchronous event queue for immediate mode tracing.
 *
 * Provides non-blocking event enqueueing with background thread writing.
 * Used in immediate and hybrid tracing modes to avoid blocking traced threads.
 */
struct AsyncQueue {
    std::mutex mtx;                             ///< Protects queue access
    std::vector<Event> queue;                   ///< Event queue
    std::condition_variable cv;                 ///< Notifies writer thread of new events
    std::atomic<bool> running{false};           ///< Writer thread running flag
    std::thread writer_thread;                  ///< Background writer thread
    FILE* output_file = nullptr;                ///< Output file stream
    std::atomic<uint64_t> enqueue_count{0};     ///< Total events enqueued (for flush_now)
    std::atomic<uint64_t> write_count{0};       ///< Total events written (for flush_now)

    // Configuration (copied from Config on start())
    int flush_interval_ms = 1;                  ///< Flush interval in milliseconds
    size_t batch_size = 128;                    ///< Max events per batch write

    /**
     * @brief Constructor (does nothing - call start() to begin).
     */
    AsyncQueue() = default;

    /**
     * @brief Destructor: Stops writer thread and flushes remaining events.
     */
    ~AsyncQueue() {
        stop();
    }

    /**
     * @brief Start the async writer thread.
     * @param out Output file stream
     */
    inline void start(FILE* out) {
        if (running.load()) return;  // Already started

        output_file = out;
        running.store(true);
        writer_thread = std::thread([this]() { writer_loop(); });
    }

    /**
     * @brief Stop the writer thread and flush remaining events.
     */
    inline void stop() {
        if (!running.load()) return;  // Not running

        running.store(false);
        cv.notify_one();

        if (writer_thread.joinable()) {
            writer_thread.join();
        }
    }

    /**
     * @brief Enqueue an event (non-blocking, called from traced threads).
     * @param e Event to enqueue
     */
    inline void enqueue(const Event& e) {
        {
            std::lock_guard<std::mutex> lock(mtx);
            queue.push_back(e);
        }
        enqueue_count.fetch_add(1, std::memory_order_relaxed);
        cv.notify_one();
    }

    /**
     * @brief Force immediate flush of queue (blocks until empty).
     *
     * Waits up to 1 second for queue to drain. Used when synchronous
     * semantics are needed (e.g., before crash, in tests).
     */
    inline void flush_now() {
        // Wake up writer thread
        cv.notify_one();

        // Spin-wait until queue is drained (or timeout)
        auto start = std::chrono::steady_clock::now();
        while (enqueue_count.load(std::memory_order_relaxed) !=
               write_count.load(std::memory_order_relaxed)) {
            std::this_thread::sleep_for(std::chrono::microseconds(100));

            // Timeout after 1 second
            auto elapsed = std::chrono::steady_clock::now() - start;
            if (elapsed > std::chrono::seconds(1)) {
                std::fprintf(stderr, "trace-scope: Warning: flush_immediate_queue() timeout after 1s\n");
                break;
            }
        }
    }

private:
    /**
     * @brief Background writer thread loop.
     *
     * Waits for events with timeout (flush_interval_ms), drains queue,
     * and writes all events to file in a batch.
     */
    inline void writer_loop() {
        while (running.load(std::memory_order_relaxed)) {
            std::vector<Event> local;

            {
                std::unique_lock<std::mutex> lock(mtx);

                // Wait with timeout for new events
                cv.wait_for(lock, std::chrono::milliseconds(flush_interval_ms),
                           [this]() {
                               return !queue.empty() || !running.load(std::memory_order_relaxed);
                           });

                // Swap queues (fast, O(1))
                local.swap(queue);
            }

            // Write all events (outside lock - no contention with enqueue)
            for (const auto& e : local) {
                if (output_file) {
                    print_event(e, output_file);
                }
            }

            // Flush to disk and update write counter
            if (!local.empty() && output_file) {
                std::fflush(output_file);
                write_count.fetch_add(local.size(), std::memory_order_relaxed);
            }
        }

        // Final flush on shutdown - ensure no events lost
        std::vector<Event> remaining;
        {
            std::lock_guard<std::mutex> lock(mtx);
            remaining.swap(queue);
        }

        for (const auto& e : remaining) {
            if (output_file) {
                print_event(e, output_file);
            }
        }

        if (!remaining.empty() && output_file) {
            std::fflush(output_file);
            write_count.fetch_add(remaining.size(), std::memory_order_relaxed);
        }
    }
};


// Forward declarations
struct Config;
struct FunctionStats;
struct AsyncQueue;

// Forward declarations for functions
inline Config& get_config();
inline void print_event(const Event& e, FILE* out);
inline void flush_current_thread();
inline AsyncQueue& async_queue();
inline bool should_trace(const char* func, const char* file, int depth);
inline uint64_t get_current_rss();

/**
 * @brief Per-thread ring buffer for trace events.
 *
 * Each thread gets its own Ring (thread_local storage). Events are written
 * lock-free to the ring buffer. When the buffer fills, oldest events are
 * overwritten (wraps counter increments).
 *
 * Supports optional double-buffering mode (see Config::use_double_buffering):
 * - Single buffer: Events written directly to buf[0], flushed in-place (default)
 * - Double buffer: Two buffers alternate; write to one while flushing the other
 */
struct Ring {
    Event       buf[TRC_NUM_BUFFERS][TRC_RING_CAP];  ///< Circular buffer(s): [0] for single mode, [0]/[1] for double mode
    uint32_t    head[TRC_NUM_BUFFERS] = {0};            ///< Next write position per buffer
    uint64_t    wraps[TRC_NUM_BUFFERS] = {0};           ///< Number of buffer wraparounds per buffer
#if TRC_DOUBLE_BUFFER
    std::atomic<int> active_buf{0};                 ///< Active buffer index for double-buffering (0 or 1)
    std::mutex  flush_mtx;                          ///< Protects buffer swap during flush (double-buffer mode only)
#endif
    int         depth = 0;                          ///< Current call stack depth
    uint32_t    tid   = 0;                          ///< Thread ID (cached)
    uint8_t     color_offset = 0;                   ///< Thread-specific color offset (0-7) for visual distinction
    bool        registered = false;                 ///< Whether this ring is registered globally
    uint64_t    start_stack[TRC_DEPTH_MAX];       ///< Start timestamp per depth (for duration calculation)
    const char* func_stack[TRC_DEPTH_MAX];        ///< Function name per depth (for message context)

    /**
     * @brief Constructor: Initialize thread-specific values.
     * Defined after thread_id_hash() declaration.
     */
    Ring();

    /**
     * @brief Destructor: Unregister from global registry.
     *
     * When a thread exits, its thread_local Ring is destroyed. We remove it
     * from the global registry to prevent flush_all() from accessing freed memory.
     *
     * Note: Any unflushed events in this ring will be lost. Applications should
     * call flush_all() or enable auto_flush_at_exit before threads terminate.
     */
    inline ~Ring();  // Defined after registry() declaration

    /**
     * @brief Check if ring buffer should be auto-flushed (hybrid mode).
     *
     * Returns true if hybrid mode is enabled and buffer usage exceeds
     * the configured threshold.
     *
     * @return true if buffer should be flushed
     */
    inline bool should_auto_flush() const;

    /**
     * @brief Write a trace event (Enter/Exit/Msg).
     *
     * In immediate mode, prints directly. In buffered mode, writes to ring buffer.
     * Maintains call stack depth and tracks start times for duration calculation.
     *
     * @param type Event type (Enter/Exit/Msg)
     * @param func Function name (null for Msg)
     * @param file Source file path
     * @param line Source line number
     */
    inline void write(EventType type, const char* func, const char* file, int line);

    /**
     * @brief Write a formatted message event.
     *
     * Retrieves current function context from the function stack and
     * formats the message using vsnprintf. In immediate mode, prints directly.
     * In buffered mode, writes to ring buffer.
     *
     * @param file Source file path
     * @param line Source line number
     * @param fmt Printf-style format string
     * @param ap Variable argument list
     */
    inline void write_msg(const char* file, int line, const char* fmt, va_list ap);
};


// Forward declarations
struct Ring;

/**
 * @brief Global registry of all thread-local ring buffers.
 *
 * Tracks all active ring buffers for flush_all() operations.
 * In DLL shared mode, manages heap-allocated Rings per thread.
 */
struct Registry {
    std::mutex mtx;                 ///< Protects rings vector and thread_rings map
    std::vector<Ring*> rings;       ///< Pointers to all registered ring buffers
    std::map<std::thread::id, Ring*> thread_rings;  ///< Thread ID to Ring mapping for DLL sharing

    /**
     * @brief Register a new ring buffer.
     * @param r Pointer to ring buffer (must remain valid)
     */
    inline void add(Ring* r) {
        std::lock_guard<std::mutex> lock(mtx);
        rings.push_back(r);
    }

    /**
     * @brief Unregister a ring buffer (called from Ring destructor).
     * @param r Pointer to ring buffer to remove
     */
    inline void remove(Ring* r) {
        std::lock_guard<std::mutex> lock(mtx);
        rings.erase(std::remove(rings.begin(), rings.end(), r), rings.end());
    }

    /**
     * @brief Get or create Ring for current thread (DLL shared mode).
     *
     * In DLL shared mode, Rings are heap-allocated and managed by the Registry
     * to ensure all DLLs access the same Ring per thread.
     *
     * @return Pointer to Ring for current thread (never null)
     */
    inline Ring* get_or_create_thread_ring() {
        std::thread::id tid = std::this_thread::get_id();

        std::lock_guard<std::mutex> lock(mtx);

        // Check if Ring already exists for this thread
        auto it = thread_rings.find(tid);
        if (it != thread_rings.end()) {
            return it->second;
        }

        // Create new Ring on heap
        Ring* ring = new Ring();
        thread_rings[tid] = ring;
        rings.push_back(ring);  // Also add to flush list
        ring->registered = true;

        return ring;
    }

    /**
     * @brief Remove Ring for specific thread (DLL shared mode cleanup).
     *
     * Called when a thread exits in DLL shared mode. Removes the Ring from
     * both the thread_rings map and the rings vector, then deletes it.
     *
     * @param tid Thread ID to remove
     */
    inline void remove_thread_ring(std::thread::id tid) {
        std::lock_guard<std::mutex> lock(mtx);

        auto it = thread_rings.find(tid);
        if (it != thread_rings.end()) {
            Ring* ring = it->second;

            // Remove from both collections
            rings.erase(std::remove(rings.begin(), rings.end(), ring), rings.end());
            thread_rings.erase(it);

            // Delete the heap-allocated Ring
            delete ring;
        }
    }
};


// Forward declarations

// Forward declarations for functions
inline Ring& thread_ring();
inline Config& get_config();
inline void flush_all();

/**
 * @brief RAII scope guard for automatic function entry/exit tracing.
 *
 * Constructs on function entry, writes Enter event, then on destruction
 * writes Exit event with calculated duration. Flush behavior is controlled
 * by the flush_mode configuration setting.
 */
struct Scope {
    const char* func;  ///< Function name
    const char* file;  ///< Source file
    int         line;  ///< Source line

    /**
     * @brief Construct a scope guard and write Enter event.
     * @param f Function name
     * @param fi Source file
     * @param li Source line
     */
    inline Scope(const char* f, const char* fi, int li) : func(f), file(fi), line(li) {
#if TRC_ENABLED
        thread_ring().write(EventType::Enter, func, file, line);
#endif
    }

    /**
     * @brief Destruct the scope guard and write Exit event.
     *
     * Writes Exit event with calculated duration. Flush behavior is
     * controlled by the flush_mode configuration setting.
     */
    inline ~Scope() {
#if TRC_ENABLED
        Ring& r = thread_ring();
        r.write(EventType::Exit, func, file, line);

        Config& cfg = get_config();
        if (cfg.flush_mode == FlushMode::EVERY_SCOPE) {
            flush_all();
        } else if (cfg.flush_mode == FlushMode::OUTERMOST_ONLY && r.depth == 0) {
            flush_all();
        }
#endif
    }
};


// Forward declarations
struct Registry;

/**
 * @brief Global configuration instance.
 *
 * Default configuration used when no external state is set.
 * Can be overridden by set_external_state() for DLL shared mode.
 */
inline Config config;

/**
 * @brief Global registry instance.
 *
 * Manages all thread-local ring buffers for flush operations.
 * In DLL shared mode, this is replaced by the shared registry.
 */
inline Registry& registry() {
    static Registry r;
    return r;
}

/**
 * @brief Global async queue instance.
 *
 * Used for immediate and hybrid tracing modes to provide
 * non-blocking event output via background writer thread.
 */
inline AsyncQueue& async_queue() {
    static AsyncQueue q;
    return q;
}

/**
 * @brief Statistics registration flag.
 *
 * Tracks whether atexit handler has been registered for
 * automatic statistics printing on program exit.
 */
static bool stats_registered = false;


// Forward declarations
struct ThreadStats;

// Forward declarations for utility functions
namespace filter_utils {
    inline bool should_trace(const char* func, const char* file, int depth) {
        // Simple implementation - always trace for now
        return true;
    }
}

namespace memory_utils {
    inline uint64_t get_current_rss() {
#ifdef _WIN32
        PROCESS_MEMORY_COUNTERS pmc;
        if (GetProcessMemoryInfo(GetCurrentProcess(), &pmc, sizeof(pmc))) {
            return pmc.WorkingSetSize;
        }
#elif defined(__linux__)
        FILE* f = fopen("/proc/self/status", "r");
        if (f) {
            char line[256];
            while (fgets(line, sizeof(line), f)) {
                if (strncmp(line, "VmRSS:", 6) == 0) {
                    uint64_t rss_kb;
                    if (sscanf(line + 6, "%lu", &rss_kb) == 1) {
                        fclose(f);
                        return rss_kb * 1024;  // Convert KB to bytes
                    }
                }
            }
            fclose(f);
        }
#elif defined(__APPLE__)
        struct task_basic_info info;
        mach_msg_type_number_t size = sizeof(info);
        if (task_info(mach_task_self(), MACH_TASK_BASIC_INFO, (task_info_t)&info, &size) == KERN_SUCCESS) {
            return info.resident_size;
        }
#endif
        return 0;
    }
}

namespace dll_shared_state {
    inline Registry* get_shared_registry() {
        // Simple implementation - return nullptr for now (no shared state)
        return nullptr;
    }
}

// Global variable declarations (from variables.hpp)
extern Config config;

// Essential utility functions
inline uint32_t thread_id_hash() {
    auto id = std::this_thread::get_id();
    return static_cast<uint32_t>(std::hash<std::thread::id>{}(id));
}

inline const char* base_name(const char* p) {
    if (!p) return "";

    const char* last_slash = std::strrchr(p, '/');
    const char* last_backslash = std::strrchr(p, '\\');

    const char* last_sep = last_slash > last_backslash ? last_slash : last_backslash;
    return last_sep ? last_sep + 1 : p;
}

// Configuration functions
inline Config& get_config() {
    return config;  // Simplified for now
}

// Registry functions - defined in variables.hpp

// Async queue functions - defined in variables.hpp

// Thread ring functions
inline Ring& thread_ring() {
    static thread_local Ring ring;
    static thread_local bool inited = false;
    if (!inited) {
        ring.tid = thread_id_hash();
        ring.color_offset = static_cast<uint8_t>(ring.tid % 8);
        registry().add(&ring);
        ring.registered = true;
        inited = true;
    }
    return ring;
}

// Flush functions
inline void flush_ring(Ring& r) {
    static std::mutex io_mtx;
    std::lock_guard<std::mutex> lock(io_mtx);

    Config& cfg = get_config();
    FILE* out = cfg.out ? cfg.out : stdout;

    // Simple flush implementation
    uint32_t start = 0;
    uint32_t count = r.head[0];

    if (r.wraps[0] > 0) {
        start = r.head[0];
        count = TRC_RING_CAP;
    }

    for (uint32_t i = 0; i < count; ++i) {
        uint32_t idx = (start + i) % TRC_RING_CAP;
        print_event(r.buf[0][idx], out);
    }

    // Reset buffer
    r.head[0] = 0;
    r.wraps[0] = 0;

    std::fflush(out);
}

inline void flush_all() {
    std::vector<Ring*> snapshot;
    {
        std::lock_guard<std::mutex> lock(registry().mtx);
        snapshot = registry().rings;
    }

    for (Ring* r : snapshot) {
        if (r) {
            flush_ring(*r);
        }
    }
}

inline void flush_current_thread() {
    flush_ring(thread_ring());
}

// Binary dump functions
inline std::string generate_dump_filename(const char* prefix = nullptr) {
    Config& cfg = get_config();
    if (!prefix) prefix = cfg.dump_prefix;

    // Generate timestamp
    auto now = std::chrono::system_clock::now();
    auto time_t = std::chrono::system_clock::to_time_t(now);
    auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(
        now.time_since_epoch()) % 1000;

    char timestamp[64];
    std::strftime(timestamp, sizeof(timestamp), "%Y%m%d_%H%M%S", std::localtime(&time_t));

    // Generate filename
    std::string filename = prefix;
    filename += "_";
    filename += timestamp;
    filename += "_";
    filename += std::to_string(ms.count());
    filename += cfg.dump_suffix;

    return filename;
}

inline std::string dump_binary(const char* prefix = nullptr) {
    std::string filename = generate_dump_filename(prefix);

    Config& cfg = get_config();
    FILE* f = safe_fopen(filename.c_str(), "wb");
    if (!f) {
        std::fprintf(stderr, "trace-scope: Error: Could not create dump file: %s\n", filename.c_str());
        return "";
    }

    // Write header
    std::fprintf(f, "TRC_BINARY_V1\n");
    std::fprintf(f, "VERSION=%s\n", TRC_SCOPE_VERSION);
    std::fprintf(f, "TIMESTAMP=%llu\n",
        static_cast<unsigned long long>(std::chrono::duration_cast<std::chrono::milliseconds>(
            std::chrono::system_clock::now().time_since_epoch()).count()));

    std::fclose(f);
    return filename;
}

// Ring method implementations
inline Ring::Ring() {
    tid = thread_id_hash();
    color_offset = (uint8_t)(tid % 8);  // Assign color offset based on thread ID
}

inline Ring::~Ring() {
    // In centralized DLL mode, Registry manages cleanup via remove_thread_ring()
    // Don't unregister here as it would cause double-removal
    if (registered && !dll_shared_state::get_shared_registry()) {
        registry().remove(this);
        registered = false;
    }
}

inline bool Ring::should_auto_flush() const {
    if (get_config().mode != TracingMode::Hybrid) {
        return false;
    }

    // Check active buffer usage
    int buf_idx = 0;
#if TRC_DOUBLE_BUFFER
    if (get_config().use_double_buffering) {
        buf_idx = active_buf.load(std::memory_order_relaxed);
    }
#endif
    float usage = (float)head[buf_idx] / (float)TRC_RING_CAP;
    if (wraps[buf_idx] > 0) {
        usage = 1.0f;  // Already wrapped = 100% full
    }

    return usage >= get_config().auto_flush_threshold;
}

inline void Ring::write(EventType type, const char* func, const char* file, int line) {
#if TRC_ENABLED
        // Apply filters - skip if filtered out, but still update depth
        if (!filter_utils::should_trace(func, file, depth)) {
            // Must still track depth to maintain correct nesting
            if (type == EventType::Enter) {
                int d = depth;
                if (d < TRC_DEPTH_MAX) {
                    const auto now = std::chrono::system_clock::now().time_since_epoch();
                    uint64_t now_ns = (uint64_t)std::chrono::duration_cast<std::chrono::nanoseconds>(now).count();
                    start_stack[d] = now_ns;
                    func_stack[d] = func;
                }
                ++depth;
            }
            else if (type == EventType::Exit) {
                depth = std::max(0, depth - 1);
            }
            return;  // Filtered out - don't write event
        }

        const auto now = std::chrono::system_clock::now().time_since_epoch();
        uint64_t now_ns = (uint64_t)std::chrono::duration_cast<std::chrono::nanoseconds>(now).count();

        Event e;
        e.ts_ns = now_ns;
        e.func  = func;
        e.file  = file;
        e.line  = line;
        e.tid   = tid;
        e.color_offset = color_offset;
        e.type  = type;
        e.msg[0]= '\0';
        e.dur_ns= 0;

        // Sample memory if tracking is enabled
        if (get_config().track_memory) {
            e.memory_rss = memory_utils::get_current_rss();
        } else {
            e.memory_rss = 0;
        }

        if (type == EventType::Enter) {
            int d = depth;
            e.depth = d;
            if (d < TRC_DEPTH_MAX) {
                start_stack[d] = now_ns;
                func_stack[d] = func;  // Track function name for messages
            }
            ++depth;
        } else if (type == EventType::Exit) {
            depth = std::max(0, depth - 1);
            int d = std::max(0, depth);
            e.depth = d;
            if (d < TRC_DEPTH_MAX) {
                uint64_t start_ns = start_stack[d];
                e.dur_ns = now_ns - start_ns;
            }
        } else {
            e.depth = depth;
        }

        // Hybrid mode: buffer AND print immediately, with auto-flush
        if (get_config().mode == TracingMode::Hybrid) {
            // Write to ring buffer first (single or double-buffer mode)
            int buf_idx = 0;
#if TRC_DOUBLE_BUFFER
            if (get_config().use_double_buffering) {
                buf_idx = active_buf.load(std::memory_order_relaxed);
            }
#else
            if (get_config().use_double_buffering) {
                static bool warned = false;
                if (!warned) {
                    std::fprintf(stderr, "trace-scope: ERROR: use_double_buffering=true but not compiled with TRC_DOUBLE_BUFFER=1\n");
                    std::fprintf(stderr, "trace-scope: Recompile with -DTRC_DOUBLE_BUFFER=1 or add before include\n");
                    warned = true;
                }
            }
#endif
            buf[buf_idx][head[buf_idx]] = e;
            head[buf_idx] = (head[buf_idx] + 1) % TRC_RING_CAP;
            if (head[buf_idx] == 0) {
                ++wraps[buf_idx];
            }

            // Check if we need to auto-flush BEFORE acquiring lock
            bool needs_flush = should_auto_flush();

            // Also print immediately for real-time visibility (using async queue)
            {
                // Ensure async queue is started (thread-safe via std::call_once)
                static std::once_flag async_init_flag;
                std::call_once(async_init_flag, []() {
                    FILE* imm_out = get_config().immediate_out;
                    if (!imm_out) {
                        imm_out = get_config().out ? get_config().out : stdout;
                    }
                    async_queue().flush_interval_ms = get_config().immediate_flush_interval_ms;
                    async_queue().batch_size = get_config().immediate_queue_size;
                    async_queue().start(imm_out);

                    // Register atexit handler to stop async queue on exit
                    std::atexit([]() {
                        if (get_config().mode == TracingMode::Hybrid) {
                            async_queue().stop();  // Stops thread and flushes remaining events
                        }
                    });
                });

                // Enqueue event for async immediate output (non-blocking)
                async_queue().enqueue(e);
            }

            // Auto-flush if buffer is near capacity (outside lock to avoid deadlock)
            if (needs_flush) {
                flush_current_thread();
            }
        }
        // Immediate mode: async queue with background writer (non-blocking)
        else if (get_config().mode == TracingMode::Immediate) {
            // Ensure async queue is started (thread-safe via std::call_once)
            static std::once_flag async_init_flag;
            std::call_once(async_init_flag, []() {
                FILE* out = get_config().out ? get_config().out : stdout;
                async_queue().flush_interval_ms = get_config().immediate_flush_interval_ms;
                async_queue().batch_size = get_config().immediate_queue_size;
                async_queue().start(out);

                // Register atexit handler to stop async queue on exit
                std::atexit([]() {
                    if (get_config().mode == TracingMode::Immediate) {
                        async_queue().stop();  // Stops thread and flushes remaining events
                    }
                });
            });

            // Enqueue event (non-blocking, fast)
            async_queue().enqueue(e);
        }
        // Buffered mode: write to ring buffer only (single or double-buffer mode)
        else {
            int buf_idx = 0;
#if TRC_DOUBLE_BUFFER
            if (get_config().use_double_buffering) {
                buf_idx = active_buf.load(std::memory_order_relaxed);
            }
#endif
            buf[buf_idx][head[buf_idx]] = e;
            head[buf_idx] = (head[buf_idx] + 1) % TRC_RING_CAP;
            if (head[buf_idx] == 0) {
                ++wraps[buf_idx];
            }
        }
#endif
    }

inline void Ring::write_msg(const char* file, int line, const char* fmt, va_list ap) {
        // Get current function name from the stack (depth is at current scope)
        const char* current_func = nullptr;
        int d = depth > 0 ? depth - 1 : 0;
        if (d < TRC_DEPTH_MAX) {
            current_func = func_stack[d];
        }

        // Hybrid mode: buffer AND print immediately
        if (get_config().mode == TracingMode::Hybrid) {
            // Create event and format message
            const auto now = std::chrono::system_clock::now().time_since_epoch();
            uint64_t now_ns = (uint64_t)std::chrono::duration_cast<std::chrono::nanoseconds>(now).count();

            Event e;
            e.ts_ns = now_ns;
            e.func = current_func;
            e.file = file;
            e.line = line;
            e.tid = tid;
            e.color_offset = color_offset;
            e.type = EventType::Msg;
            e.depth = depth;
            e.dur_ns = 0;
            e.memory_rss = 0;

            // Format the message
            if (!fmt) {
                e.msg[0] = 0;
            }
            else {
                int n = std::vsnprintf(e.msg, TRC_MSG_CAP, fmt, ap);
                if (n < 0) {
                    e.msg[0] = 0;
                }
                else {
                    e.msg[std::min(n, TRC_MSG_CAP)] = 0;
                }
            }

            // Write to buffer
            int buf_idx = 0;
#if TRC_DOUBLE_BUFFER
            if (get_config().use_double_buffering) {
                buf_idx = active_buf.load(std::memory_order_relaxed);
            }
#endif
            buf[buf_idx][head[buf_idx]] = e;
            head[buf_idx] = (head[buf_idx] + 1) % TRC_RING_CAP;
            if (head[buf_idx] == 0) {
                ++wraps[buf_idx];
            }

            // Also enqueue to async queue for immediate output
            async_queue().enqueue(e);

            // Check for auto-flush
            if (should_auto_flush()) {
                flush_current_thread();
            }
        }
        // Immediate mode: format and enqueue to async queue (non-blocking)
        else if (get_config().mode == TracingMode::Immediate) {
            const auto now = std::chrono::system_clock::now().time_since_epoch();
            uint64_t now_ns = (uint64_t)std::chrono::duration_cast<std::chrono::nanoseconds>(now).count();

            Event e;
            e.ts_ns = now_ns;
            e.func = current_func;
            e.file = file;
            e.line = line;
            e.tid = tid;
            e.color_offset = color_offset;
            e.type = EventType::Msg;
            e.depth = depth;
            e.dur_ns = 0;
            e.memory_rss = 0;

            if (!fmt) {
                e.msg[0] = 0;
            }
            else {
                int n = std::vsnprintf(e.msg, TRC_MSG_CAP, fmt, ap);
                if (n < 0) {
                    e.msg[0] = 0;
                }
                else {
                    e.msg[std::min(n, TRC_MSG_CAP)] = 0;
                }
            }

            // Enqueue to async queue (non-blocking, fast)
            async_queue().enqueue(e);
        }
        // Buffered mode: write to ring buffer only
        else {
            write(EventType::Msg, current_func, file, line);
            int buf_idx = 0;
#if TRC_DOUBLE_BUFFER
            if (get_config().use_double_buffering) {
                buf_idx = active_buf.load(std::memory_order_relaxed);
            }
#endif
            Event& e = buf[buf_idx][(head[buf_idx] + TRC_RING_CAP - 1) % TRC_RING_CAP];

            if (!fmt) {
                e.msg[0] = 0;
                return;
            }

            int n = std::vsnprintf(e.msg, TRC_MSG_CAP, fmt, ap);
            if (n < 0) {
                e.msg[0] = 0;
            }
            else {
                e.msg[std::min(n, TRC_MSG_CAP)] = 0;
            }
        }
    }

// Print event function
inline void print_event(const Event& e, FILE* out) {
    // ANSI color for depth-based colorization with thread-aware offset
    if (get_config().colorize_depth) {
        // Combine depth and thread offset for visual distinction
        // Each thread gets a unique color offset, making multi-threaded traces easier to read
        int color_idx = (e.depth + e.color_offset) % 8;
        static const char* colors[] = {
            "\033[31m",  // Red
            "\033[32m",  // Green
            "\033[33m",  // Yellow
            "\033[34m",  // Blue
            "\033[35m",  // Magenta
            "\033[36m",  // Cyan
            "\033[37m",  // White
            "\033[91m"   // Bright Red
        };
        std::fprintf(out, "%s", colors[color_idx]);
    }

    if (get_config().print_timestamp) {
        // Convert ns timestamp to human-readable ISO format with milliseconds
        auto duration = std::chrono::nanoseconds(e.ts_ns);
        auto tp = std::chrono::time_point<std::chrono::system_clock, std::chrono::nanoseconds>(duration);
        auto time_t_val = std::chrono::system_clock::to_time_t(
            std::chrono::time_point_cast<std::chrono::system_clock::duration>(tp));
        auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(duration) % 1000;

        std::tm tm_buf;
        #ifdef _WIN32
        localtime_s(&tm_buf, &time_t_val);
        #else
        localtime_r(&time_t_val, &tm_buf);
        #endif

        std::fprintf(out, "[%04d-%02d-%02d %02d:%02d:%02d.%03d] ",
            tm_buf.tm_year + 1900, tm_buf.tm_mon + 1, tm_buf.tm_mday,
            tm_buf.tm_hour, tm_buf.tm_min, tm_buf.tm_sec, (int)ms.count());
    }
    if (get_config().print_thread)    std::fprintf(out, "(%08x) ", e.tid);

    // Filename:line:function prefix block (fixed widths), before indent so alignment is stable
    if (get_config().include_file_line && e.file) {
        bool printed_something = false;

        // Print filename if enabled
        if (get_config().include_filename) {
            const char* path = get_config().show_full_path ? e.file : base_name(e.file);
            const int fw = (get_config().filename_width > 0 ? get_config().filename_width : 20);

            // Head-truncate: show beginning of path (precision limits max chars printed)
            std::fprintf(out, "%-*.*s", fw, fw, path);
            printed_something = true;
        }

        // Print line number and function name if enabled (they're paired)
        if (get_config().include_function_name) {
            const int lw = (get_config().line_width > 0 ? get_config().line_width : 5);
            const int funcw = (get_config().function_width > 0 ? get_config().function_width : 20);
            const char* fname = e.func ? e.func : "";

            // Print colon separator if filename was printed
            if (printed_something) std::fprintf(out, ":");

            // Print line number
            std::fprintf(out, "%*d", lw, e.line);

            // Head-truncate function name: show beginning (precision limits max chars)
            std::fprintf(out, " %-*.*s", funcw, funcw, fname);
            printed_something = true;
        }

        if (printed_something) std::fprintf(out, " ");
    }

    // Depth indentation after prefix
    if (get_config().show_indent_markers) {
        // Show visual markers for each level
        const char* marker = get_config().indent_marker ? get_config().indent_marker : "| ";
        for (int i = 0; i < e.depth; ++i) {
            std::fputs(marker, out);
        }
    } else {
        // Plain whitespace indentation
        for (int i = 0; i < e.depth; ++i) {
            std::fputs("  ", out);
        }
    }

    // Event type markers
    const char* enter_mk = get_config().enter_marker ? get_config().enter_marker : "-> ";
    const char* exit_mk = get_config().exit_marker ? get_config().exit_marker : "<- ";
    const char* msg_mk = get_config().msg_marker ? get_config().msg_marker : "- ";

    switch (e.type) {
    case EventType::Enter:
        std::fprintf(out, "%s%s", enter_mk, e.func);
        break;
    case EventType::Exit:
        if (get_config().print_timing) {
            // Auto-scale units based on duration
            if (e.dur_ns < 1000ULL) {
                std::fprintf(out, "%s%s  [%llu ns]", exit_mk, e.func, (unsigned long long)e.dur_ns);
            } else if (e.dur_ns < 1000000ULL) {
                std::fprintf(out, "%s%s  [%.2f us]", exit_mk, e.func, e.dur_ns / 1000.0);
            } else if (e.dur_ns < 1000000000ULL) {
                std::fprintf(out, "%s%s  [%.2f ms]", exit_mk, e.func, e.dur_ns / 1000000.0);
            } else {
                std::fprintf(out, "%s%s  [%.3f s]", exit_mk, e.func, e.dur_ns / 1000000000.0);
            }
        } else {
            std::fprintf(out, "%s%s", exit_mk, e.func);
        }
        break;
    case EventType::Msg:
        std::fprintf(out, "%s%s", msg_mk, e.msg[0] ? e.msg : "");
        break;
    }

    // Reset color and add newline
    if (get_config().colorize_depth) {
        std::fprintf(out, "\033[0m");  // Reset to default color
    }
    std::fprintf(out, "\n");
}

// Message functions
inline void trace_msgf(const char* file, int line, const char* fmt, ...) {
#if TRC_ENABLED
    va_list ap;
    va_start(ap, fmt);
    thread_ring().write_msg(file, line, fmt, ap);
    va_end(ap);
#endif
}

template<typename T>
inline void trace_arg(const char* file, int line, const char* name, const char* type_name, const T& value) {
#if TRC_ENABLED
    std::ostringstream oss;
    oss << name << "[" << type_name << "]=" << value;
    trace_msgf(file, line, "%s", oss.str().c_str());
#endif
}

inline void trace_arg(const char* file, int line, const char* name, const char* type_name) {
#if TRC_ENABLED
    trace_msgf(file, line, "%s[%s]=<unknown>", name, type_name);
#endif
}

// Missing functions that were in original header
inline void set_external_state(Config* cfg, Registry* reg) {
    dll_shared_state::set_shared_config(cfg);
    dll_shared_state::set_shared_registry(reg);
}

inline bool load_config(const char* path) {
    return get_config().load_from_file(path);
}

inline void filter_include_function(const char* pattern) {
    config.filter.include_functions.push_back(pattern);
}

inline void filter_exclude_function(const char* pattern) {
    config.filter.exclude_functions.push_back(pattern);
}

inline void filter_include_file(const char* pattern) {
    config.filter.include_files.push_back(pattern);
}

inline void filter_exclude_file(const char* pattern) {
    config.filter.exclude_files.push_back(pattern);
}

inline void filter_set_max_depth(int depth) {
    config.filter.max_depth = depth;
}

inline void filter_clear() {
    config.filter.include_functions.clear();
    config.filter.exclude_functions.clear();
    config.filter.include_files.clear();
    config.filter.exclude_files.clear();
    config.filter.max_depth = -1;
}

inline void flush_immediate_queue() {
    if (config.mode == TracingMode::Immediate) {
        async_queue().flush_now();
    }
}

inline void start_async_immediate(FILE* out = nullptr) {
    if (config.mode == TracingMode::Immediate) {
        async_queue().start(out);
    }
}

inline void stop_async_immediate() {
    if (config.mode == TracingMode::Immediate) {
        async_queue().stop();
    }
}

inline void ensure_stats_registered() {
    if (!stats_registered) {
        stats_registered = true;
        // Register atexit handler for stats
        std::atexit([]() {
            if (config.mode != TracingMode::Disabled) {
                dump_stats();
            }
        });
    }
}

inline std::string generate_dump_filename(const char* prefix = nullptr) {
    namespace fs = std::filesystem;

    if (!prefix) prefix = get_config().dump_prefix;
    const char* suffix = get_config().dump_suffix;

    auto now = std::chrono::system_clock::now();
    auto time_t_val = std::chrono::system_clock::to_time_t(now);
    auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(
        now.time_since_epoch()) % 1000;

    std::tm tm;
#ifdef _WIN32
    localtime_s(&tm, &time_t_val);
#else
    localtime_r(&time_t_val, &tm);
#endif

    // Build base path
    fs::path base_path;
    if (get_config().output_dir) {
        base_path = get_config().output_dir;
    } else {
        base_path = ".";
    }

    // Add subdirectory based on layout
    fs::path dir_path;
    switch (get_config().output_layout) {
        case Config::OutputLayout::ByDate: {
            // Subdirectory: YYYY-MM-DD
            char date_buf[32];
            std::snprintf(date_buf, sizeof(date_buf), "%04d-%02d-%02d",
                          tm.tm_year + 1900, tm.tm_mon + 1, tm.tm_mday);
            dir_path = base_path / date_buf;
            break;
        }
        case Config::OutputLayout::BySession: {
            // Subdirectory: session_NNN
            int session = get_config().current_session;

            // Auto-increment: find max existing session number
            if (session == 0) {
                int max_session = 0;
                try {
                    if (fs::exists(base_path)) {
                        for (const auto& entry : fs::directory_iterator(base_path)) {
                            if (entry.is_directory()) {
                                std::string dirname = entry.path().filename().string();
                                if (dirname.substr(0, 8) == "session_") {
                                    int num = std::atoi(dirname.substr(8).c_str());
                                    max_session = std::max(max_session, num);
                                }
                            }
                        }
                    }
                } catch (...) {
                    // Ignore errors during auto-detection
                }
                session = max_session + 1;
            }

            char session_buf[32];
            std::snprintf(session_buf, sizeof(session_buf), "session_%03d", session);
            dir_path = base_path / session_buf;
            break;
        }
        case Config::OutputLayout::Flat:
        default:
            // No subdirectory
            dir_path = base_path;
            break;
    }

    // Create directory if it doesn't exist
    try {
        if (!dir_path.empty() && !fs::exists(dir_path)) {
            fs::create_directories(dir_path);
        }
    } catch (const std::exception& e) {
        std::fprintf(stderr, "trace-scope: Failed to create directory %s: %s\n",
                     dir_path.string().c_str(), e.what());
        // Fall back to current directory
        dir_path = ".";
    }

    // Generate filename
    char filename_buf[256];
    std::snprintf(filename_buf, sizeof(filename_buf), "%s_%04d%02d%02d_%02d%02d%02d_%03d%s",
                  prefix,
                  tm.tm_year + 1900, tm.tm_mon + 1, tm.tm_mday,
                  tm.tm_hour, tm.tm_min, tm.tm_sec,
                  (int)ms.count(),
                  suffix);

    fs::path full_path = dir_path / filename_buf;
    return full_path.string();
}

inline std::string dump_binary(const char* prefix = nullptr) {
    std::string filename = generate_dump_filename(prefix);
    FILE* f = safe_fopen(filename.c_str(), "wb");
    if (!f) return "";

    auto w8  = [&](uint8_t v){ std::fwrite(&v,1,1,f); };
    auto w16 = [&](uint16_t v){ std::fwrite(&v,1,2,f); };
    auto w32 = [&](uint32_t v){ std::fwrite(&v,1,4,f); };
    auto w64 = [&](uint64_t v){ std::fwrite(&v,1,8,f); };
    auto ws  = [&](const char* s, uint16_t n){ if (n) std::fwrite(s,1,n,f); };

    std::fwrite("TRCLOG10",1,8,f);
    w32(2); // version (bumped to 2 for color_offset field)
    w32(0);

    std::vector<Ring*> snapshot;
    { std::lock_guard<std::mutex> lock(registry().mtx); snapshot = registry().rings; }

    for (Ring* r : snapshot) {
        if (!r || !r->registered) continue;

        // Determine which buffer(s) to dump
        int num_buffers = TRC_NUM_BUFFERS;
#if TRC_DOUBLE_BUFFER
        if (!get_config().use_double_buffering) {
            num_buffers = 1;
        }
#endif

        for (int buf = 0; buf < num_buffers; ++buf) {
            const Event* events = r->buffers[buf];
            uint32_t count = r->counts[buf];
            uint32_t head = r->heads[buf];

            if (count == 0) continue;

            // Write thread info
            w32(r->thread_id);
            ws(r->thread_name.c_str(), static_cast<uint16_t>(r->thread_name.length()));
            w8(0); // null terminator

            // Write events
            w32(count);
            for (uint32_t i = 0; i < count; ++i) {
                uint32_t idx = (head - count + i + TRC_RING_CAP) % TRC_RING_CAP;
                const Event& e = events[idx];

                w8(static_cast<uint8_t>(e.type));
                w64(e.timestamp);
                w32(e.depth);
                w32(e.color_offset);
                ws(e.function, static_cast<uint16_t>(std::strlen(e.function)));
                ws(e.file, static_cast<uint16_t>(std::strlen(e.file)));
                w32(e.line);
                ws(e.message, static_cast<uint16_t>(std::strlen(e.message)));
            }
        }
    }

    std::fclose(f);
    return filename;
}

namespace internal {

// Flag to ensure we only register once
static bool stats_registered = false;

// Exit handler function
inline void stats_exit_handler() {
    if (get_config().print_stats) {
        stats::print_stats(get_config().out ? get_config().out : stderr);
    }
}

// Register exit handler if stats are enabled
inline void ensure_stats_registered() {
    if (!stats_registered && get_config().print_stats) {
        std::atexit(stats_exit_handler);
        stats_registered = true;
    }
}

} // namespace internal

namespace dll_shared_state {
    // Shared state structure
    struct SharedTraceState {
        uint32_t magic;
        uint32_t version;
        Config* config_ptr;
        Registry* registry_ptr;
        char process_name[64];
    };

    // Get or create shared state (thread-safe)
    inline SharedTraceState* get_shared_state() {
        static std::mutex init_mutex;
        static SharedTraceState* state = nullptr;
        static shared_memory::SharedMemoryHandle shm_handle;

        if (state) return state;

        std::lock_guard<std::mutex> lock(init_mutex);
        if (state) return state;  // Double-check

        // Try to open existing shared memory first (DLL case)
        std::string shm_name = shared_memory::get_shared_memory_name();
        shm_handle = shared_memory::create_or_open_shared_memory(
            shm_name.c_str(),
            sizeof(SharedTraceState),
            false  // Try open first
        );

        if (!shm_handle.valid) {
            // Doesn't exist, we might be the first/main EXE
            // This is OK - will be created by TRC_SETUP_DLL_SHARED()
            return nullptr;
        }

        // Access shared memory
        state = static_cast<SharedTraceState*>(shared_memory::get_mapped_address(shm_handle));

        // Validate magic number
        if (state->magic != 0x54524143) {  // "TRAC"
            state = nullptr;  // Invalid shared memory
        }

        return state;
    }

    inline Config* get_shared_config() {
        SharedTraceState* state = get_shared_state();
        return state ? state->config_ptr : nullptr;
    }

    inline Registry* get_shared_registry() {
        SharedTraceState* state = get_shared_state();
        return state ? state->registry_ptr : nullptr;
    }

    inline void set_shared_config(Config* cfg) {
        SharedTraceState* state = get_shared_state();
        if (state) state->config_ptr = cfg;
    }

    inline void set_shared_registry(Registry* reg) {
        SharedTraceState* state = get_shared_state();
        if (state) state->registry_ptr = reg;
    }
}


// Forward declarations
struct Scope;
inline void trace_msgf(const char* file, int line, const char* fmt, ...);
template<typename T>
inline void trace_arg(const char* file, int line, const char* name, const char* type, const T& value);
inline void trace_arg(const char* file, int line, const char* name, const char* type);
template<typename Container>
inline std::string format_container(const Container& c, size_t max_elem = 5);

/**
 * @brief Stream-based logging class for TRC_LOG macro.
 *
 * Provides C++ iostream-style logging using operator<<. Drop-in replacement
 * for stream-based logging macros. The message is associated with the
 * current function and displayed at the current indentation depth.
 */
struct TraceStream {
    std::ostringstream ss;  ///< Stream buffer for collecting output
    const char* file;       ///< Source file path
    int line;               ///< Source line number

    /**
     * @brief Constructor.
     * @param f Source file path
     * @param l Source line number
     */
    TraceStream(const char* f, int l) : file(f), line(l) {}

    /**
     * @brief Destructor: Outputs collected message.
     */
    ~TraceStream() {
        trace_msgf(file, line, "%s", ss.str().c_str());
    }

    /**
     * @brief Stream insertion operator.
     * @tparam T Type of value to insert
     * @param val Value to insert
     * @return Reference to this stream
     */
    template<typename T>
    TraceStream& operator<<(const T& val) {
        ss << val;
        return *this;
    }
};


} // namespace trace

// Macros (outside namespace)
#define TRC_SCOPE() ::trace::Scope _trace_scope_obj(__func__, __FILE__, __LINE__)
#define TRC_MSG(...) ::trace::trace_msgf(__FILE__, __LINE__, __VA_ARGS__)
#define TRC_LOG ::trace::TraceStream(__FILE__, __LINE__)
#define TRC_CONTAINER(container, max_elements) ::trace::format_container(container, max_elements)
#define TRC_ARG(...) ::trace::trace_arg(__FILE__, __LINE__, __VA_ARGS__)
#define TRC_SETUP_DLL_SHARED_WITH_CONFIG(config_file) \
    static trace::Config g_trace_shared_config; \
    static trace::Registry g_trace_shared_registry; \
    static trace::shared_memory::SharedMemoryHandle g_shm_handle; \
    static trace::dll_shared_state::SharedTraceState* g_shared_state = nullptr; \
    static struct TraceDllGuard { \
        TraceDllGuard() { \
            /* Create shared memory */ \
            std::string shm_name = trace::shared_memory::get_shared_memory_name(); \
            g_shm_handle = trace::shared_memory::create_or_open_shared_memory( \
                shm_name.c_str(), \
                sizeof(trace::dll_shared_state::SharedTraceState), \
                true /* create */ \
            ); \
            \
            if (g_shm_handle.valid) { \
                /* Initialize shared state */ \
                g_shared_state = static_cast<trace::dll_shared_state::SharedTraceState*>( \
                    trace::shared_memory::get_mapped_address(g_shm_handle)); \
                g_shared_state->magic = 0x54524143; \
                g_shared_state->version = 1; \
                g_shared_state->config_ptr = &g_trace_shared_config; \
                g_shared_state->registry_ptr = &g_trace_shared_registry; \
                std::strncpy(g_shared_state->process_name, "trace-scope", 63); \
                g_shared_state->process_name[63] = '\0'; \
            } \
            \
            trace::set_external_state(&g_trace_shared_config, &g_trace_shared_registry); \
            const char* cfg_path = (config_file); \
            if (cfg_path && cfg_path[0]) { \
                g_trace_shared_config.load_from_file(cfg_path); \
            } \
        } \
        ~TraceDllGuard() { \
            trace::flush_all(); \
            if (g_shm_handle.valid) { \
                trace::shared_memory::close_shared_memory(g_shm_handle); \
            } \
        } \
    } g_trace_dll_guard;
#define TRC_SETUP_DLL_SHARED() TRC_SETUP_DLL_SHARED_WITH_CONFIG(nullptr)

